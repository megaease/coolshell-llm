{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2be30e87-b232-48c4-a08c-480769fbde26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bitsandbytes>=0.39.0 in /usr/local/lib/python3.10/site-packages (0.42.0)\n",
      "Requirement already satisfied: loralib in /usr/local/lib/python3.10/site-packages (0.1.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/site-packages (from bitsandbytes>=0.39.0) (1.12.0)\n",
      "Requirement already satisfied: numpy<1.29.0,>=1.22.4 in /usr/local/lib/python3.10/site-packages (from scipy->bitsandbytes>=0.39.0) (1.26.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: transformers<4.35.0,>=4.31.0 in /usr/local/lib/python3.10/site-packages (4.34.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers<4.35.0,>=4.31.0) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/site-packages (from transformers<4.35.0,>=4.31.0) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/site-packages (from transformers<4.35.0,>=4.31.0) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from transformers<4.35.0,>=4.31.0) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.35.0,>=4.31.0) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers<4.35.0,>=4.31.0) (2023.12.25)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from transformers<4.35.0,>=4.31.0) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/site-packages (from transformers<4.35.0,>=4.31.0) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.35.0,>=4.31.0) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/site-packages (from transformers<4.35.0,>=4.31.0) (4.66.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers<4.35.0,>=4.31.0) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers<4.35.0,>=4.31.0) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests->transformers<4.35.0,>=4.31.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests->transformers<4.35.0,>=4.31.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->transformers<4.35.0,>=4.31.0) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests->transformers<4.35.0,>=4.31.0) (2023.7.22)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: datasets>=2.14.3 in /usr/local/lib/python3.10/site-packages (2.14.7)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/site-packages (from datasets>=2.14.3) (1.26.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/site-packages (from datasets>=2.14.3) (15.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/site-packages (from datasets>=2.14.3) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from datasets>=2.14.3) (0.3.7)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/site-packages (from datasets>=2.14.3) (2.2.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/site-packages (from datasets>=2.14.3) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/site-packages (from datasets>=2.14.3) (4.66.2)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/site-packages (from datasets>=2.14.3) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/site-packages (from datasets>=2.14.3) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets>=2.14.3) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/site-packages (from datasets>=2.14.3) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/site-packages (from datasets>=2.14.3) (0.17.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/site-packages (from datasets>=2.14.3) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from datasets>=2.14.3) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets>=2.14.3) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets>=2.14.3) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets>=2.14.3) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets>=2.14.3) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets>=2.14.3) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets>=2.14.3) (4.0.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets>=2.14.3) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets>=2.14.3) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests>=2.19.0->datasets>=2.14.3) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests>=2.19.0->datasets>=2.14.3) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests>=2.19.0->datasets>=2.14.3) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests>=2.19.0->datasets>=2.14.3) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/site-packages (from pandas->datasets>=2.14.3) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas->datasets>=2.14.3) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/site-packages (from pandas->datasets>=2.14.3) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.14.3) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/site-packages (0.27.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/site-packages (from accelerate>=0.21.0) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from accelerate>=0.21.0) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/site-packages (from accelerate>=0.21.0) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/site-packages (from accelerate>=0.21.0) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/site-packages (from accelerate>=0.21.0) (2.2.0)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/site-packages (from accelerate>=0.21.0) (0.17.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/site-packages (from accelerate>=0.21.0) (0.4.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.21.0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.21.0) (4.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.21.0) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.21.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.21.0) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.21.0) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.21.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.21.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.21.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.21.0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.21.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.21.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.21.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.21.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.21.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.21.0) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.21.0) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.21.0) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate>=0.21.0) (12.3.101)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from huggingface-hub->accelerate>=0.21.0) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/site-packages (from huggingface-hub->accelerate>=0.21.0) (4.66.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate>=0.21.0) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate>=0.21.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate>=0.21.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate>=0.21.0) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate>=0.21.0) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate>=0.21.0) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: peft==0.8.1 in /usr/local/lib/python3.10/site-packages (0.8.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/site-packages (from peft==0.8.1) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from peft==0.8.1) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/site-packages (from peft==0.8.1) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/site-packages (from peft==0.8.1) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/site-packages (from peft==0.8.1) (2.2.0)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/site-packages (from peft==0.8.1) (4.34.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (from peft==0.8.1) (4.66.2)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/site-packages (from peft==0.8.1) (0.27.0)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/site-packages (from peft==0.8.1) (0.4.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/site-packages (from peft==0.8.1) (0.17.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.8.1) (3.13.1)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.8.1) (2023.10.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.8.1) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.8.1) (4.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.8.1) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.8.1) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.8.1) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.8.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.8.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.8.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.8.1) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.8.1) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.8.1) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.8.1) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.8.1) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.8.1) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.8.1) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.8.1) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.8.1) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft==0.8.1) (12.3.101)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers->peft==0.8.1) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/site-packages (from transformers->peft==0.8.1) (0.14.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.8.1) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.8.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.8.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.8.1) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.8.1) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft==0.8.1) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: trl>=0.7.4 in /usr/local/lib/python3.10/site-packages (0.7.10)\n",
      "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/site-packages (from trl>=0.7.4) (2.2.0)\n",
      "Requirement already satisfied: transformers>=4.31.0 in /usr/local/lib/python3.10/site-packages (from trl>=0.7.4) (4.34.1)\n",
      "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.10/site-packages (from trl>=0.7.4) (1.26.1)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/site-packages (from trl>=0.7.4) (0.27.0)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/site-packages (from trl>=0.7.4) (2.14.7)\n",
      "Requirement already satisfied: tyro>=0.5.11 in /usr/local/lib/python3.10/site-packages (from trl>=0.7.4) (0.7.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from torch>=1.4.0->trl>=0.7.4) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/site-packages (from torch>=1.4.0->trl>=0.7.4) (4.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/site-packages (from torch>=1.4.0->trl>=0.7.4) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/site-packages (from torch>=1.4.0->trl>=0.7.4) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from torch>=1.4.0->trl>=0.7.4) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/site-packages (from torch>=1.4.0->trl>=0.7.4) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch>=1.4.0->trl>=0.7.4) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch>=1.4.0->trl>=0.7.4) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch>=1.4.0->trl>=0.7.4) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/site-packages (from torch>=1.4.0->trl>=0.7.4) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/site-packages (from torch>=1.4.0->trl>=0.7.4) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/site-packages (from torch>=1.4.0->trl>=0.7.4) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/site-packages (from torch>=1.4.0->trl>=0.7.4) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/site-packages (from torch>=1.4.0->trl>=0.7.4) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/site-packages (from torch>=1.4.0->trl>=0.7.4) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/site-packages (from torch>=1.4.0->trl>=0.7.4) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch>=1.4.0->trl>=0.7.4) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/site-packages (from torch>=1.4.0->trl>=0.7.4) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4.0->trl>=0.7.4) (12.3.101)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/site-packages (from transformers>=4.31.0->trl>=0.7.4) (0.17.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from transformers>=4.31.0->trl>=0.7.4) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers>=4.31.0->trl>=0.7.4) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers>=4.31.0->trl>=0.7.4) (2023.12.25)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from transformers>=4.31.0->trl>=0.7.4) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/site-packages (from transformers>=4.31.0->trl>=0.7.4) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/site-packages (from transformers>=4.31.0->trl>=0.7.4) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/site-packages (from transformers>=4.31.0->trl>=0.7.4) (4.66.2)\n",
      "Requirement already satisfied: docstring-parser>=0.14.1 in /usr/local/lib/python3.10/site-packages (from tyro>=0.5.11->trl>=0.7.4) (0.15)\n",
      "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/site-packages (from tyro>=0.5.11->trl>=0.7.4) (13.7.0)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/site-packages (from tyro>=0.5.11->trl>=0.7.4) (1.6.5)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/site-packages (from accelerate->trl>=0.7.4) (5.9.6)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/site-packages (from datasets->trl>=0.7.4) (15.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/site-packages (from datasets->trl>=0.7.4) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from datasets->trl>=0.7.4) (0.3.7)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/site-packages (from datasets->trl>=0.7.4) (2.2.0)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/site-packages (from datasets->trl>=0.7.4) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/site-packages (from datasets->trl>=0.7.4) (0.70.15)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/site-packages (from datasets->trl>=0.7.4) (3.9.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets->trl>=0.7.4) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets->trl>=0.7.4) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets->trl>=0.7.4) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets->trl>=0.7.4) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets->trl>=0.7.4) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets->trl>=0.7.4) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl>=0.7.4) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl>=0.7.4) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl>=0.7.4) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl>=0.7.4) (2023.7.22)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl>=0.7.4) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl>=0.7.4) (2.16.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->torch>=1.4.0->trl>=0.7.4) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/site-packages (from pandas->datasets->trl>=0.7.4) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas->datasets->trl>=0.7.4) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/site-packages (from pandas->datasets->trl>=0.7.4) (2024.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/site-packages (from sympy->torch>=1.4.0->trl>=0.7.4) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl>=0.7.4) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl>=0.7.4) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/site-packages (0.1.99)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install \"bitsandbytes>=0.39.0\" loralib\n",
    "!pip install \"transformers>=4.31.0,<4.35.0\"\n",
    "!pip install \"datasets>=2.14.3\"\n",
    "!pip install \"accelerate>=0.21.0\"\n",
    "!pip install \"peft==0.8.1\"\n",
    "!pip install \"trl>=0.7.4\"\n",
    "!pip install \"sentencepiece\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6484fca3-cdc4-4ef1-9ebb-aa06c36ab98a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4616b6-db8d-4b41-a93d-a8c75e0dbae5",
   "metadata": {},
   "source": [
    "### load tokenizer\n",
    "The `AutoTokenizer.from_pretrained()` function is used to load the tokenizer that corresponds to the pre-trained model. The tokenizer is responsible for converting input text into a format that the model can understand. The `trust_remote_code=True` argument allows the execution of remote code, which can be necessary if the tokenizer includes custom (non-standard) components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "972e20e3-41c8-4fd1-a6f8-114eb09f4cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from typing import List, Union, Dict\n",
    "\n",
    "model_to_load = \"THUDM/chatglm3-6b\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_to_load, trust_remote_code=True)\n",
    "\n",
    "prefix: List[Union[str, Dict[str, str]]] =[\n",
    "        {\"token\": \"[gMASK]\"},\n",
    "        {\"token\": \"sop\"},\n",
    "        {\"token\": \"<|user|>\"},\n",
    "        \"\\n\",\n",
    "        \"{{question}}\",\n",
    "        {\"token\": \"<|assistant|>\"}\n",
    "]\n",
    "\n",
    "eos_ids = [] if tokenizer.eos_token_id is None else [tokenizer.eos_token_id]\n",
    "bos_ids = [] if tokenizer.bos_token_id is None else [tokenizer.bos_token_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0084b6-697c-4013-8f17-3eac278197a0",
   "metadata": {},
   "source": [
    "### load dataset\n",
    "This cell code snippet is using the `load_dataset` function from the `datasets` library to load a JSON dataset from a local file named 'qa.json'. The `load_dataset` function returns a `Dataset` object.\n",
    "\n",
    "The `Dataset` object, `qa_dataset`, has its columns renamed for clarity and consistency. The 'instruction' column is renamed to 'question', the 'input' column is renamed to 'context', and the 'output' column is renamed to 'answers'. The `rename_column` method is used to perform these renamings. It takes two arguments: the current name of the column and the new name for the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a822edf4-2d2f-48cf-a484-67a7a9c7fc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "qa_dataset = load_dataset('json', data_files='qa.json')\n",
    "qa_dataset = qa_dataset.rename_column('instruction',  'question')\\\n",
    "        .rename_column('input', 'context')\\\n",
    "        .rename_column('output','answers')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194659ec-a98e-426f-acf7-33c301183f6e",
   "metadata": {},
   "source": [
    "### processing dataset\n",
    "\n",
    "The cell code is responsible for processing a dataset for pretraining a language model. Here's a breakdown of the main parts:\n",
    "\n",
    "- create_prompt(question) -> List[int]: This function takes a question as input and returns a list of integers. It iterates over the prefix (which is not defined in the selection), and for each part of the prefix, it checks if it's a dictionary. If it is, it converts the \"token\" value to IDs using the tokenizer. If it's not a dictionary, it replaces \"{{question}}\" with the actual question and encodes it to IDs. The result is a list of token IDs that represent the prompt.\n",
    "- process_pretrain_dataset(example: \"Dataset\") -> Dict[str, List[List[int]]]: This function processes the dataset for pretraining. It takes a dataset example as input and returns a dictionary with keys \"input_ids\", \"attention_mask\", and \"labels\". It defines a generator function construct_prompt that yields context, question, and answer from the example. For each context, question, and answer, it creates a tokenized prompt and response, constructs the input IDs, labels, and attention mask, and appends them to the result dictionary.\n",
    "- print_supervised_dataset_example(example: Dict[str, List[int]]) -> None: This function prints an example from the processed dataset. It prints the input IDs, the decoded inputs, the label IDs, and the decoded labels (excluding those with a value of -100).\n",
    "- The last two lines of the selection map the process_pretrain_dataset function to the qa_dataset, removing the 'answers', 'context', and 'question' columns. It then prints the mapped dataset and an example from the \"train\" split of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efb5e7a9-c89e-42cc-8465-2762bc57230f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 701\n",
      "    })\n",
      "})\n",
      "input_ids:\n",
      "[64790, 64792, 64795, 30910, 13, 9751, 35623, 32495, 64796, 36953, 31211, 55266, 58091, 31123, 55419, 38019, 56264, 54583, 13, 30595, 39288, 32366, 31301, 31865, 55090, 31300, 13, 30939, 9751, 10913, 3974, 2331, 30932, 9549, 9007, 359, 1556, 3341, 28670, 1460, 30945, 13, 33775, 54781, 30595, 36223, 35541, 54631, 40536, 31123, 54532, 30595, 19277, 39288, 32330, 54530, 35084, 54642, 31668, 34651, 31155, 32763, 45257, 32330, 54586, 41618, 38064, 54945, 37927, 31123, 33775, 45904, 31846, 31155, 13, 30943, 21209, 9751, 30932, 5096, 9007, 359, 1556, 18349, 1223, 4733, 30945, 13, 33775, 35344, 54534, 30595, 39288, 54538, 30981, 30973, 54907, 39685, 35549, 38809, 32035, 33257, 31123, 31704, 32035, 33257, 51637, 33125, 31936, 31698, 32096, 54626, 33142, 32184, 54530, 34980, 31155, 13, 30966, 9751, 7652, 328, 7524, 291, 12299, 359, 1556, 7992, 1536, 19366, 30945, 13, 54534, 33775, 54538, 31123, 31704, 34076, 32715, 54530, 32320, 54631, 31892, 32929, 54537, 32542, 33706, 31750, 31624, 31201, 31750, 31695, 31123, 31701, 31123, 54656, 44502, 54537, 32320, 32542, 33438, 31123, 32784, 37604, 31735, 32026, 31155, 13, 30972, 9751, 9867, 3741, 773, 30954, 2870, 1083, 30932, 19146, 17581, 293, 22232, 29210, 359, 1556, 18349, 1223, 4733, 30945, 13, 30595, 54635, 55250, 54530, 38799, 32698, 46224, 31001, 30595, 9867, 3741, 8526, 31123, 10122, 5349, 38753, 32981, 31155, 13, 30970, 21305, 291, 9751, 359, 1556, 10744, 397, 731, 308, 30945, 13, 33775, 39920, 31879, 32443, 41664, 32852, 49595, 31123, 32493, 33671, 58728, 57708, 38123, 31123, 54534, 30949, 30777, 397, 731, 308, 48746, 49927, 34757, 54603, 54617, 53226, 39288, 54825, 55071, 33268, 32190, 35589, 54579, 42255, 31155, 13, 32132, 31211, 56594, 57034, 54766, 13393, 8103, 602, 13, 2]\n",
      "inputs:\n",
      "[gMASK]sop<|user|> \n",
      " Java书籍推荐<|assistant|> 作者：陈皓，左耳朵耗子\n",
      "Java编程规范（第三版）\n",
      "1 Java Language Specification, Third Edition (by James Gosling)\n",
      "本书由Java技术的发明者编写，是Java TM编程语言的权威性技术指南。如果你想知道语言之构造的精确含义，本书是最好的资源。\n",
      "2 Effective Java, Second Edition (by Joshua Bloch)\n",
      "本书介绍了在Java编程中78条极具实用价值的经验规则，这些经验规则涵盖了大多数开发人员每天所面临的问题的解决方案。\n",
      "3 Java Concurrency in Practice (by Brian Goetz)\n",
      "在本书中，这些便利工具的创造者不仅解释了它们究竟如何工作、如何使用，同时，还阐释了创造它们的原因，及其背后的设计模式。\n",
      "4 Java Puzzles: Traps, Pitfalls and Corner Cases (by Joshua Bloch)\n",
      "Java教父的又一经典名著–Java Puzzlers，Amazon五星图书。\n",
      "5 Thinking in Java (by Bruce Eckel)\n",
      "本书赢得了全球程序员的广泛赞誉，即使是最晦涩的概念，在Bruce Eckel的文字亲和力和小而直接的编程示例面前也会化解于无形。\n",
      "来自：酷壳网 CoolShell\n",
      "\n",
      "label_ids:\n",
      "[-100, -100, -100, -100, -100, -100, -100, -100, -100, 36953, 31211, 55266, 58091, 31123, 55419, 38019, 56264, 54583, 13, 30595, 39288, 32366, 31301, 31865, 55090, 31300, 13, 30939, 9751, 10913, 3974, 2331, 30932, 9549, 9007, 359, 1556, 3341, 28670, 1460, 30945, 13, 33775, 54781, 30595, 36223, 35541, 54631, 40536, 31123, 54532, 30595, 19277, 39288, 32330, 54530, 35084, 54642, 31668, 34651, 31155, 32763, 45257, 32330, 54586, 41618, 38064, 54945, 37927, 31123, 33775, 45904, 31846, 31155, 13, 30943, 21209, 9751, 30932, 5096, 9007, 359, 1556, 18349, 1223, 4733, 30945, 13, 33775, 35344, 54534, 30595, 39288, 54538, 30981, 30973, 54907, 39685, 35549, 38809, 32035, 33257, 31123, 31704, 32035, 33257, 51637, 33125, 31936, 31698, 32096, 54626, 33142, 32184, 54530, 34980, 31155, 13, 30966, 9751, 7652, 328, 7524, 291, 12299, 359, 1556, 7992, 1536, 19366, 30945, 13, 54534, 33775, 54538, 31123, 31704, 34076, 32715, 54530, 32320, 54631, 31892, 32929, 54537, 32542, 33706, 31750, 31624, 31201, 31750, 31695, 31123, 31701, 31123, 54656, 44502, 54537, 32320, 32542, 33438, 31123, 32784, 37604, 31735, 32026, 31155, 13, 30972, 9751, 9867, 3741, 773, 30954, 2870, 1083, 30932, 19146, 17581, 293, 22232, 29210, 359, 1556, 18349, 1223, 4733, 30945, 13, 30595, 54635, 55250, 54530, 38799, 32698, 46224, 31001, 30595, 9867, 3741, 8526, 31123, 10122, 5349, 38753, 32981, 31155, 13, 30970, 21305, 291, 9751, 359, 1556, 10744, 397, 731, 308, 30945, 13, 33775, 39920, 31879, 32443, 41664, 32852, 49595, 31123, 32493, 33671, 58728, 57708, 38123, 31123, 54534, 30949, 30777, 397, 731, 308, 48746, 49927, 34757, 54603, 54617, 53226, 39288, 54825, 55071, 33268, 32190, 35589, 54579, 42255, 31155, 13, 32132, 31211, 56594, 57034, 54766, 13393, 8103, 602, 13, 2]\n",
      "labels:\n",
      "作者：陈皓，左耳朵耗子\n",
      "Java编程规范（第三版）\n",
      "1 Java Language Specification, Third Edition (by James Gosling)\n",
      "本书由Java技术的发明者编写，是Java TM编程语言的权威性技术指南。如果你想知道语言之构造的精确含义，本书是最好的资源。\n",
      "2 Effective Java, Second Edition (by Joshua Bloch)\n",
      "本书介绍了在Java编程中78条极具实用价值的经验规则，这些经验规则涵盖了大多数开发人员每天所面临的问题的解决方案。\n",
      "3 Java Concurrency in Practice (by Brian Goetz)\n",
      "在本书中，这些便利工具的创造者不仅解释了它们究竟如何工作、如何使用，同时，还阐释了创造它们的原因，及其背后的设计模式。\n",
      "4 Java Puzzles: Traps, Pitfalls and Corner Cases (by Joshua Bloch)\n",
      "Java教父的又一经典名著–Java Puzzlers，Amazon五星图书。\n",
      "5 Thinking in Java (by Bruce Eckel)\n",
      "本书赢得了全球程序员的广泛赞誉，即使是最晦涩的概念，在Bruce Eckel的文字亲和力和小而直接的编程示例面前也会化解于无形。\n",
      "来自：酷壳网 CoolShell\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from typing import TYPE_CHECKING, Any, Dict, Generator, List, Literal, Tuple, Union\n",
    "def create_prompt(question) -> List[int]:\n",
    "    result = []\n",
    "    for prefix_part in prefix:\n",
    "        if isinstance(prefix_part, dict):\n",
    "            if \"token\" in prefix_part:\n",
    "                result += [tokenizer.convert_tokens_to_ids(prefix_part[\"token\"])]\n",
    "            else:\n",
    "                result += [tokenizer.convert_tokens_to_ids(prefix_part[\"token\"])]\n",
    "        else:\n",
    "            prefix_part = prefix_part.replace(\"{{question}}\", question, 1)\n",
    "            result += tokenizer.encode(prefix_part, add_special_tokens=False)\n",
    "    return  result\n",
    "\n",
    "def process_pretrain_dataset(example: \"Dataset\") -> Dict[str, List[List[int]]]:\n",
    "    result = {\"input_ids\": [], \"attention_mask\": [], \"labels\": []}\n",
    "    def construct_prompt(example: Dict[str, Union[str, List[str]]]) -> Generator[str, None, None]:\n",
    "        for i in range(len(example[\"question\"])):\n",
    "            context = example[\"context\"][i]\n",
    "            question = example[\"question\"][i]\n",
    "            answer = example[\"answers\"][i]\n",
    "            yield context, question, answer\n",
    "    \n",
    "    for context, question, answer in construct_prompt(example):\n",
    "        tokenized_prompt = create_prompt(question)\n",
    "        tokenized_resp = tokenizer.encode(answer, add_special_tokens=False)\n",
    "        input_ids = bos_ids  + tokenized_prompt + tokenized_resp + eos_ids\n",
    "        labels = bos_ids + [-100] * (len(tokenized_prompt)) + tokenized_resp + eos_ids\n",
    "        attention_mask = [1]*len(input_ids)\n",
    "        result[\"input_ids\"].append(input_ids)\n",
    "        result[\"attention_mask\"].append(attention_mask)\n",
    "        result[\"labels\"].append(labels)\n",
    "\n",
    "    return result\n",
    "\n",
    "def print_supervised_dataset_example(example: Dict[str, List[int]]) -> None:\n",
    "    print(\"input_ids:\\n{}\".format(example[\"input_ids\"]))\n",
    "    print(\"inputs:\\n{}\".format(tokenizer.decode(example[\"input_ids\"], skip_special_tokens=False)))\n",
    "    print(\"label_ids:\\n{}\".format(example[\"labels\"]))\n",
    "    print(\"labels:\\n{}\".format(\n",
    "        tokenizer.decode(list(filter(lambda x: x != -100, example[\"labels\"])), skip_special_tokens=False)\n",
    "    ))\n",
    "\n",
    "mapped_qa_dataset = qa_dataset.map(process_pretrain_dataset, remove_columns=['answers', 'context', 'question'], batched=True)\n",
    "print(mapped_qa_dataset)\n",
    "print_supervised_dataset_example(next(iter(mapped_qa_dataset[\"train\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd8bcb0-ed11-466c-9f62-49118d5ec44a",
   "metadata": {},
   "source": [
    "### load pretrained model\n",
    "\n",
    "This cell is responsible for loading a pre-trained model and its corresponding tokenizer. \n",
    "\n",
    "The variable `model_to_load` is set to the string \"THUDM/chatglm3-6b\", which is likely the identifier of a pre-trained model stored in a model hub or a local directory.\n",
    "\n",
    "The `AutoModelForCausalLM.from_pretrained()` function is used to load the pre-trained model. This function is part of the `transformers` library and is designed to handle models that are used for causal language modeling tasks. The arguments passed to this function configure the model's behavior:\n",
    "\n",
    "- `model_to_load` specifies the model to load.\n",
    "- `torch_dtype=torch.bfloat16` sets the data type of the model's parameters to bfloat16, a floating-point format that provides better performance on some hardware.\n",
    "- `device_map='cuda:0'` specifies that the model should be loaded onto the first CUDA device, if available.\n",
    "- `trust_remote_code=True` allows the execution of remote code, which can be necessary if the model includes custom (non-standard) components.\n",
    "- `revision=\"b098244a71fbe69ce149682d9072a7629f7e908c\"` specifies a particular version of the model to load, identified by its commit hash.\n",
    "- `quantization_config=BitsAndBytesConfig(...)` sets the configuration for quantization, a technique used to reduce the memory footprint of the model. The `BitsAndBytesConfig` object is configured to use 4-bit quantization, with bfloat16 as the compute data type, and to use double quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2acd1b8f-832c-4ece-8edc-c84857831e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 7fd43a9b-381f-47d7-b247-61095a970f8d)')' thrown while requesting HEAD https://huggingface.co/THUDM/chatglm3-6b/resolve/main/adapter_config.json\n",
      "/usr/local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/usr/local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: e7238674-9536-4e63-8ef3-1773dfb52b8a)')' thrown while requesting HEAD https://huggingface.co/THUDM/chatglm3-6b/resolve/main/adapter_config.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6421da505e234972a56e5e9c881b97f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import bitsandbytes as bnb\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_to_load, \n",
    "                                             torch_dtype=torch.bfloat16, \n",
    "                                             device_map='cuda:0',\n",
    "                                             trust_remote_code=True,\n",
    "                                             revision=\"b098244a71fbe69ce149682d9072a7629f7e908c\",\n",
    "                                             quantization_config=BitsAndBytesConfig(load_in_4bit=True,\n",
    "                                                               bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "                                                               bnb_4bit_use_double_quant=True,\n",
    "                                                               bnb_4bit_quant_type=\"nf4\")\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29f6a82b-26eb-40df-9455-024478f732a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGLMForConditionalGeneration(\n",
      "  (transformer): ChatGLMModel(\n",
      "    (embedding): Embedding(\n",
      "      (word_embeddings): Embedding(65024, 4096)\n",
      "    )\n",
      "    (rotary_pos_emb): RotaryEmbedding()\n",
      "    (encoder): GLMTransformer(\n",
      "      (layers): ModuleList(\n",
      "        (0-27): 28 x GLMBlock(\n",
      "          (input_layernorm): RMSNorm()\n",
      "          (self_attention): SelfAttention(\n",
      "            (query_key_value): Linear4bit(in_features=4096, out_features=4608, bias=True)\n",
      "            (core_attention): CoreAttention(\n",
      "              (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (dense): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          )\n",
      "          (post_attention_layernorm): RMSNorm()\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear4bit(in_features=4096, out_features=27392, bias=False)\n",
      "            (dense_4h_to_h): Linear4bit(in_features=13696, out_features=4096, bias=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (final_layernorm): RMSNorm()\n",
      "    )\n",
      "    (output_layer): Linear(in_features=4096, out_features=65024, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdb710d-45d9-4dfe-bd3f-34ae25a85e0c",
   "metadata": {},
   "source": [
    "### set up the model\n",
    "\n",
    "This cell snippet is part of a process known as model fine-tuning, where a pre-trained model is adapted to a new, similar task.\n",
    "\n",
    "In the first loop, the code iterates over all the parameters of the model. For each parameter, it sets `requires_grad` to `False`, effectively freezing the parameter. This means that during subsequent training, the gradients will not be computed for these parameters, and thus they will remain unchanged. This is typically done when you want to keep parts of the model fixed and only train some layers (in this case, adapters will be trained later).\n",
    "\n",
    "However, if the parameter's dimension (`ndim`) is 1, the code changes the data type of the parameter's data to `torch.float32`. This is done for stability reasons, as some parameters like those in Layer Normalization layers are sensitive to precision and can cause instability in training if kept in lower precision formats.\n",
    "\n",
    "After that, the `gradient_checkpointing_enable` method is called on the model. Gradient checkpointing is a technique to reduce the memory usage when training models, at the cost of increased computation. It reduces the number of activations that need to be stored in memory.\n",
    "\n",
    "Finally, the `enable_input_require_grads` method is called on the model. This method ensures that gradients with respect to the input are computed, which is not the default behavior in PyTorch. This might be necessary for some specific training regimes or for certain types of models.\n",
    "\n",
    "The class `CastOutputToFloat` that inherits from `nn.Sequential`, a container class in the PyTorch library. The `nn.Sequential`  class is used to encapsulate a sequence of modules where the output of one module is the input to the next one.\n",
    "\n",
    "The `forward` method is overridden in the `CastOutputToFloat` class. This method is called when you pass an input to an instance of the class. The `forward` method takes an input `x`, passes it to the `forward` method of the superclass (`nn.Sequential`), and then converts the output to `torch.float32` data type using the `to` method. This is done to ensure that the output of the model is always in floating point format, which is necessary for many downstream tasks in machine learning.\n",
    "\n",
    "The last line of the code is replacing the `output_layer` of the `model.transformer` with an instance of `CastOutputToFloat`. This means that whenever the output layer of the transformer model is called, it will now use the `forward` method defined in `CastOutputToFloat`, thus ensuring that its output is always a floating point tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acf4a730-4bdb-4368-9077-896245315121",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False #freeze the model - train adapters later\n",
    "    if param.ndim == 1:\n",
    "        # cast the small parameters (e.g. layernorm) to fp32 for stability\n",
    "        param.data = param.data.to(torch.float32)\n",
    "    \n",
    "model.gradient_checkpointing_enable() #reduce number of stored activations\n",
    "model.enable_input_require_grads()\n",
    "\n",
    "class CastOutputToFloat(nn.Sequential):\n",
    "    def forward(self, x): return super().forward(x).to(torch.float32)\n",
    "model.transformer.output_layer = CastOutputToFloat(model.transformer.output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751f6104-a32f-40e4-949b-a616ba19ccc5",
   "metadata": {},
   "source": [
    "### print_trainable_parameters\n",
    "This Python function, `print_trainable_parameters`, takes a model as an argument and prints the number of trainable parameters in the model.\n",
    "\n",
    "The function initializes two counters, trainable_params and all_params, to zero. It then iterates over all the parameters of the model using the named_parameters() method. For each parameter, it adds the total number of elements in the parameter tensor to all_params using the numel() method.\n",
    "\n",
    "If the parameter requires gradient (i.e., it's trainable), the function also adds the number of elements in the parameter tensor to trainable_params.\n",
    "\n",
    "Finally, the function prints the number of trainable parameters, the total number of parameters, and the percentage of parameters that are trainable. This information can be useful for understanding the capacity of the model and how much of it is being trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64c0b752-ddd9-4c9e-b25b-3ece60cb437c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the models\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_params} || trainable %: {100 * trainable_params / all_params}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcd07e1-fb1d-4365-a9fe-c8b179a53de6",
   "metadata": {},
   "source": [
    "### configuring Lora configuration\n",
    "\n",
    "The cell code is configuring and applying a LoraConfig to a model, and then printing the number of trainable parameters in the model.\n",
    "\n",
    "First, a `LoraConfig` object is created with the following parameters:\n",
    "\n",
    "- `r`: This is set to 64. In the context of Lora (Layer-wise Learning Rate Adaptation), `r` is the rank of the low-rank approximation used in the Lora method.\n",
    "- `lora_alpha`: This is set to 32. `lora_alpha` is a hyperparameter in the Lora method that controls the learning rate adaptation.\n",
    "- `target_modules`: This is set to `[\"query_key_value\"]`. It specifies the modules in the model to which Lora should be applied.\n",
    "- `lora_dropout`: This is set to 0.05. It's the dropout rate used in the Lora method.\n",
    "- `bias`: This is set to \"none\". It specifies the type of bias to be used in the Lora method.\n",
    "- `task_type`: This is set to \"CAUSAL_LM\". It specifies the type of task the model is being trained for. In this case, it's a causal language modeling task.\n",
    "\n",
    "Next, the `get_peft_model` function is called with the `model` and `config` as arguments. This function is likely applying the Lora configuration to the model.\n",
    "\n",
    "Finally, the `print_trainable_parameters` function is called with the `model` as an argument. This function prints the number of trainable parameters in the model. This is useful for understanding the complexity of the model and how many parameters will be updated during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61f74a6f-56c6-4bd1-a91a-54f807a0380a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 15597568 || all params: 3403909120 || trainable %: 0.4582251596658374\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "config = LoraConfig(\n",
    "    r=64,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"query_key_value\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8e1ee5-04be-44c7-8e0a-16c6a169f18a",
   "metadata": {},
   "source": [
    "### load and print pretrained configuration\n",
    "\n",
    "This cell code snippet is used to load a pre-trained model configuration using the `AutoConfig.from_pretrained` method from the `transformers` library.\n",
    "\n",
    "The `model_to_load` variable is expected to be a string that specifies the model to be loaded. This could be a model ID from Hugging Face's model hub or a local path to a directory containing model files.\n",
    "\n",
    "The `config_kwargs` dictionary is used to pass additional arguments to the `from_pretrained` method. In this case, the `trust_remote_code` key is set to `True`, which means that the code will trust user code and data loaded from the Hugging Face model hub.\n",
    "\n",
    "After the configuration is loaded, it is printed to the console along with the `config_kwargs` dictionary for debugging purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "035ac91f-59f2-4a13-b50c-6f1f26ddfc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.34.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config_kwargs = {\n",
    "    \"trust_remote_code\": True,\n",
    "}\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_to_load, **config_kwargs)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3406f0d4-bacc-4f3c-a99b-2e9495c6c788",
   "metadata": {},
   "source": [
    "### setting up the training configuration\n",
    "\n",
    "This cell is setting up the training configuration for a model using the `TrainingArguments` class from the `transformers` library.\n",
    "\n",
    "- `max_steps = 6000`: This sets the total number of training steps to 6000. A training step is one gradient update. In one step, the model processes `batch_size` number of examples and updates the weights once based on the gradients computed from those `batch_size` number of examples.\n",
    "\n",
    "- `logging_steps = 100`: This sets the frequency of logging steps. The training metrics will be logged every 100 steps.\n",
    "\n",
    "- `learning_rate = 5e-5`: This sets the learning rate for the optimizer. The learning rate controls how much to change the model in response to the estimated error each time the model weights are updated.\n",
    "\n",
    "- `training_args = transformers.TrainingArguments(...)`: This creates an instance of the `TrainingArguments` class, which is used to define the training parameters. The parameters include:\n",
    "  - `per_device_train_batch_size=1`: The number of training examples utilized in one iteration per device.\n",
    "  - `gradient_accumulation_steps=1`: The number of steps to accumulate gradients before performing an optimizer step. This can be useful to handle large batches that don't fit in memory.\n",
    "  - `warmup_steps=100`: The number of steps for the warmup phase, where the learning rate increases from 0 to the initial lr set.\n",
    "  - `max_steps=max_steps`: The total number of training steps.\n",
    "  - `learning_rate=learning_rate`: The learning rate for the optimizer.\n",
    "  - `bf16=True`: Enables bfloat16 mode for training on GPUs. Bfloat16 is a compact numeric format that uses half the bits as float32 but achieves comparable model accuracy.\n",
    "  - `logging_steps=logging_steps`: The number of steps between each logging.\n",
    "  - `output_dir='outputs'`: The directory where the model predictions and checkpoints will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "348230cf-f968-4c18-b175-2850a0b2282b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "max_steps = 50000 # about seven hours\n",
    "logging_steps = 500\n",
    "learning_rate = 4e-5\n",
    "\n",
    "training_args = transformers.TrainingArguments(\n",
    "        per_device_train_batch_size=1,\n",
    "        gradient_accumulation_steps=1,\n",
    "        warmup_steps=100,\n",
    "        max_steps=max_steps,\n",
    "        learning_rate=learning_rate,\n",
    "        bf16=True,\n",
    "        logging_steps=logging_steps,\n",
    "        output_dir='outputs',\n",
    "        optim='paged_adamw_8bit',    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f9afbb-4ad0-403d-bfaa-46a3074e2fe1",
   "metadata": {},
   "source": [
    "### training the model\n",
    "\n",
    "This cell is responsible for the training of the model. \n",
    "\n",
    "The `transformers.Trainer` class from the `transformers` library is used to handle the training. It takes several arguments:\n",
    "\n",
    "- `model`: This is the model that you want to train. It's loaded from previous cell.\n",
    "- `train_dataset`: This is the dataset that you want to use for training. In this case, it's `mapped_qa_dataset[\"train\"]`, which is a dataset that has been preprocessed and tokenized.\n",
    "- `args`: These are the training arguments that define the training parameters such as the batch size, learning rate, etc. They are defined earlier in the cell code as `training_args`.\n",
    "- `data_collator`: This is used to batch data from the dataset. In this case, `transformers.DataCollatorForLanguageModeling` is used with `mlm` (Masked Language Modeling) set to `False`.\n",
    "\n",
    "After the `Trainer` is initialized, the model's caching mechanism is disabled by setting `model.config.use_cache` to `False`. This is done to save memory during training, but it might slow down the training process.\n",
    "\n",
    "Finally, the training is started with `trainer.train()`. This will train the model according to the parameters defined in `training_args` on the `train_dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9effb2-2ee7-4ee4-96c0-4433563e3389",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46474' max='50000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46474/50000 9:29:38 < 43:13, 1.36 it/s, Epoch 66.30/72]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.084300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.680800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>3.627300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.543300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>3.504100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>3.486300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>3.404600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>3.390800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>3.316400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>3.311500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>3.280700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>3.233300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>3.175600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>3.187900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>3.109400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>3.086100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>3.034400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>3.004700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>2.971100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>2.897300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>2.897800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>2.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>2.800300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>2.726700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>2.744600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>2.665100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>2.573800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>2.627200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>2.537300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>2.476500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>2.516600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>2.448100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>2.380500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>2.342800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>2.358600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>2.323300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>2.237000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>2.214900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>2.222600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>2.141800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>2.123700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>2.101300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>2.087600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>2.052600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>2.016800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>1.973900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23500</td>\n",
       "      <td>1.976400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>1.954600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24500</td>\n",
       "      <td>1.907200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>1.875800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25500</td>\n",
       "      <td>1.879300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>1.879200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26500</td>\n",
       "      <td>1.821200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>1.799900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27500</td>\n",
       "      <td>1.795800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>1.761100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28500</td>\n",
       "      <td>1.704700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>1.759600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29500</td>\n",
       "      <td>1.730900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>1.691000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30500</td>\n",
       "      <td>1.664000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>1.693500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31500</td>\n",
       "      <td>1.623100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>1.593500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32500</td>\n",
       "      <td>1.702100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>1.526500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33500</td>\n",
       "      <td>1.599600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>1.537800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34500</td>\n",
       "      <td>1.593200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>1.561000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35500</td>\n",
       "      <td>1.474900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>1.550600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36500</td>\n",
       "      <td>1.508100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37000</td>\n",
       "      <td>1.509600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37500</td>\n",
       "      <td>1.469600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>1.485900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38500</td>\n",
       "      <td>1.458200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39000</td>\n",
       "      <td>1.460600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39500</td>\n",
       "      <td>1.404400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>1.460200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40500</td>\n",
       "      <td>1.458100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41000</td>\n",
       "      <td>1.393900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41500</td>\n",
       "      <td>1.397700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>1.430900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42500</td>\n",
       "      <td>1.368700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43000</td>\n",
       "      <td>1.404900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43500</td>\n",
       "      <td>1.390000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>1.381400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44500</td>\n",
       "      <td>1.353600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>1.376100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45500</td>\n",
       "      <td>1.357700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46000</td>\n",
       "      <td>1.332700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=mapped_qa_dataset[\"train\"],\n",
    "    args=training_args,\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    ")\n",
    "#model.config.use_cache = False\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e2905b-aaec-4776-82db-70af71d546c2",
   "metadata": {},
   "source": [
    "### saving model and state\n",
    "\n",
    "The two lines of code are used to save the state of the trainer and the model after training.\n",
    "\n",
    "The trainer.save_model() function is a method from the Trainer class in the transformers library. It saves the model's weights into a directory. By default, this directory is the one defined in the output_dir attribute of the TrainingArguments object used when initializing the Trainer.\n",
    "\n",
    "The trainer.save_state() function is also a method from the Trainer class in the transformers library. It saves the optimizer and the scheduler states to ensure that you can resume training exactly where you left off. This is particularly useful when training large models that can't be trained in one go and need to be trained in several stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7754c1f2-dacc-47ab-a802-f061319ab11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d465da-5802-48b9-bf5b-3c344dc62564",
   "metadata": {},
   "source": [
    "### inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "076eaabe-1b55-49b8-8d93-94ffae01c939",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a792c962b1f04f7580b412e15de3ba45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from peft import PeftModel\n",
    "import bitsandbytes as bnb\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "model_to_load = \"THUDM/chatglm3-6b\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_to_load, \n",
    "                                             torch_dtype=torch.bfloat16, \n",
    "                                             device_map='cuda:0',\n",
    "                                             trust_remote_code=True,\n",
    "                                             revision=\"b098244a71fbe69ce149682d9072a7629f7e908c\",\n",
    "                                             quantization_config=BitsAndBytesConfig(load_in_4bit=True,\n",
    "                                                               bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "                                                               bnb_4bit_use_double_quant=True,\n",
    "                                                               bnb_4bit_quant_type=\"nf4\")\n",
    "                                            )\n",
    "\n",
    "qa_model = PeftModel.from_pretrained(model, \"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9533b8d-64bd-4604-a2b3-3fe6ef3bf76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): ChatGLMForConditionalGeneration(\n",
      "      (transformer): ChatGLMModel(\n",
      "        (embedding): Embedding(\n",
      "          (word_embeddings): Embedding(65024, 4096)\n",
      "        )\n",
      "        (rotary_pos_emb): RotaryEmbedding()\n",
      "        (encoder): GLMTransformer(\n",
      "          (layers): ModuleList(\n",
      "            (0-27): 28 x GLMBlock(\n",
      "              (input_layernorm): RMSNorm()\n",
      "              (self_attention): SelfAttention(\n",
      "                (query_key_value): lora.Linear4bit(\n",
      "                  (base_layer): Linear4bit(in_features=4096, out_features=4608, bias=True)\n",
      "                  (lora_dropout): ModuleDict(\n",
      "                    (default): Dropout(p=0.05, inplace=False)\n",
      "                  )\n",
      "                  (lora_A): ModuleDict(\n",
      "                    (default): Linear(in_features=4096, out_features=64, bias=False)\n",
      "                  )\n",
      "                  (lora_B): ModuleDict(\n",
      "                    (default): Linear(in_features=64, out_features=4608, bias=False)\n",
      "                  )\n",
      "                  (lora_embedding_A): ParameterDict()\n",
      "                  (lora_embedding_B): ParameterDict()\n",
      "                )\n",
      "                (core_attention): CoreAttention(\n",
      "                  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (dense): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "              )\n",
      "              (post_attention_layernorm): RMSNorm()\n",
      "              (mlp): MLP(\n",
      "                (dense_h_to_4h): Linear4bit(in_features=4096, out_features=27392, bias=False)\n",
      "                (dense_4h_to_h): Linear4bit(in_features=13696, out_features=4096, bias=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (final_layernorm): RMSNorm()\n",
      "        )\n",
      "        (output_layer): Linear(in_features=4096, out_features=65024, bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(qa_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ea14c57-2636-4a51-9c94-e0567b796138",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_to_load, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b043e88f-f276-4eca-8b63-60d9f5e9df7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "from typing import TYPE_CHECKING, Any, Dict, Generator, List, Literal, Tuple, Union\n",
    "\n",
    "prefix: List[Union[str, Dict[str, str]]] =[\n",
    "        {\"token\": \"[gMASK]\"},\n",
    "        {\"token\": \"sop\"},\n",
    "        {\"token\": \"<|user|>\"},\n",
    "        \"\\n\",\n",
    "        \"{{question}}\",\n",
    "        {\"token\": \"<|assistant|>\"}\n",
    "]\n",
    "\n",
    "def create_prompt(question) -> List[int]:\n",
    "    result = []\n",
    "    for prefix_part in prefix:\n",
    "        if isinstance(prefix_part, dict):\n",
    "            if \"token\" in prefix_part:\n",
    "                result += [tokenizer.convert_tokens_to_ids(prefix_part[\"token\"])]\n",
    "            else:\n",
    "                result += [tokenizer.convert_tokens_to_ids(prefix_part[\"token\"])]\n",
    "        else:\n",
    "            prefix_part = prefix_part.replace(\"{{question}}\", question, 1)\n",
    "            result += tokenizer.encode(prefix_part, add_special_tokens=False)\n",
    "    return  result\n",
    "\n",
    "\n",
    "def make_inference(question, refer_model):\n",
    "    batch = dict()\n",
    "    input_ids = create_prompt(question)\n",
    "    batch[\"input_ids\"] = torch.tensor([input_ids])\n",
    "    batch[\"attention_mask\"] = torch.tensor([[1] * len(input_ids)])\n",
    "    batch[\"position_ids\"] = torch.tensor([list(range(0, len(input_ids)))])\n",
    "    \n",
    "    print(\"question:\\n{}\".format(batch))\n",
    "    \n",
    "    with torch.cuda.amp.autocast():\n",
    "        output_tokens = refer_model.generate(**batch, max_new_tokens=512)\n",
    "    \n",
    "    print(\"output{}\".format(output_tokens))\n",
    "    display(Markdown((tokenizer.decode(output_tokens[0], skip_special_tokens=True))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cad093e-73df-47af-a795-9aec6c80f2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question:\n",
      "{'input_ids': tensor([[64790, 64792, 64795, 30910,    13, 30910, 54840, 43572, 31705, 36232,\n",
      "         46130, 32443, 54650, 31784, 32108, 55370, 64796]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'position_ids': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16]])}\n",
      "outputtensor([[64790, 64792, 64795, 30910,    13, 30910, 54840, 43572, 31705, 36232,\n",
      "         46130, 32443, 54650, 31784, 32108, 55370, 64796, 36953, 31211, 55266,\n",
      "         58091, 31123, 55419, 38019, 56264, 54583,    13, 54531, 31201, 31788,\n",
      "         31943, 31930, 31301, 31788, 31943, 33130, 31300,    13, 54534, 36232,\n",
      "         31735, 54538, 31123, 36232, 54758, 31665, 31788, 31943, 34301, 31848,\n",
      "         31123, 33740, 31668, 32924, 31848, 31301, 32098, 31943, 34301, 31943,\n",
      "         33951, 31123, 31786, 33130, 31123, 31786, 34030, 54609, 31966, 54534,\n",
      "         36232, 54538, 31123, 36232, 54758, 54552, 33351, 31711, 31943, 34301,\n",
      "         33130, 54542, 33257, 31123, 33740, 31668, 32924, 33130, 31123, 32098,\n",
      "         31123, 54622, 32253, 31665, 33351, 36954, 36577, 54530, 32912, 31765,\n",
      "         31123, 54622, 37812, 31717, 36954, 36577, 54530, 39468, 54567, 33663,\n",
      "         54537, 31155,    13, 54920, 31211, 54622, 32818, 31717, 31786, 31782,\n",
      "         31123, 33966, 54801, 31782, 31123, 31660, 31782, 31123, 31863, 31782,\n",
      "         31123, 47774, 31782, 31123, 32608, 31301, 54622, 32709, 31788, 54530,\n",
      "         31930, 54948, 36647, 31300, 30910, 31676, 54622, 32017, 54534, 36232,\n",
      "         31735, 54538, 31123, 31717, 31943, 34301, 33130, 31123, 33257, 54542,\n",
      "         31786, 34030, 54609, 33193,    13, 31301, 55535, 31211, 30910, 31939,\n",
      "         33446, 54530, 33130, 54542, 33257, 31123, 44531, 54867, 33479, 54802,\n",
      "         54701, 31788, 31704, 33257, 54542, 33130, 36577, 36577, 49108, 31765,\n",
      "         31123, 36577, 36577, 49108, 31765, 54542, 31943, 34301, 31765, 54948,\n",
      "         34243, 54537, 31123, 44531, 54867, 33479, 54802, 54701, 33650, 33650,\n",
      "         33650, 31123, 44531, 31665, 54536, 54657, 33560, 32035, 32017, 33650,\n",
      "         54607, 31841, 31123, 31939, 31665, 54536, 34548, 32091, 32035, 54701,\n",
      "         34059, 37620,    13, 54704, 31201, 31658, 31735, 32026, 31301, 31788,\n",
      "         31735, 32026, 31300,    13, 31301, 31939, 31665, 31788, 34481, 32026,\n",
      "         33445, 33445, 33445, 31123, 54622, 32994, 31665, 31788, 54542, 32687,\n",
      "         31784, 54692, 32769, 31735, 32026, 31123, 32098, 54838, 55071, 32026,\n",
      "         31123, 34130, 32026, 31123, 34130, 32026, 31123, 32778, 54631, 32026,\n",
      "         31123, 32608, 31123, 31939, 32694, 55114, 54636, 31123, 30910, 31939,\n",
      "         32495, 54778, 54613, 31824, 31702, 31735, 32026, 32924, 35623, 54611,\n",
      "         31735, 32026, 54612, 54542, 54611, 31735, 32026, 35549, 34651, 54612,\n",
      "         32283, 54622, 33780, 32869, 54611, 30951,   534, 30928,   331,   371,\n",
      "          2005, 30910, 31735, 32026, 54612, 37721, 32395, 30937, 10629, 30910,\n",
      "         32090, 32885, 54612, 54609, 31300,    13, 54920, 31211, 44531, 31717,\n",
      "         31123, 32406, 31735, 32026, 31123, 32406, 33356, 31123, 32406, 31987,\n",
      "         31123, 32406, 31943, 33130, 31123, 54549, 46386, 32406, 31735, 32026,\n",
      "         31155, 44531, 31793, 32406, 31987, 31123, 32406, 31943, 33130, 54701,\n",
      "         31768, 32406, 31735, 32026, 31123, 33740, 31123, 32341, 54563, 54571,\n",
      "         32071, 31735, 32026, 31155, 44531, 31717, 31750, 54701, 54571, 31735,\n",
      "         32026, 31301, 54622, 32994, 31665, 54549, 55172, 31784, 31735, 32026,\n",
      "         31300, 33193,    13, 32132, 31211, 56594, 57034, 54766, 13393,  8103,\n",
      "           602,    13,     2]])\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "[gMASK]sop<|user|> \n",
       " 给立志成为架构师的程序员一些建议吧<|assistant|> 作者：陈皓，左耳朵耗子\n",
       "一、了解业务领域（了解业务流程）\n",
       "在架构设计中，架构师需要了解业务领域的知识，而不是技术方面的知识（比如业务领域的业务逻辑，数据流程，数据模型等）。在架构中，架构师要关心的是业务领域的流程和规则，而不是技术方面的流程，比如，你并不需要关心数据库引擎的内部实现，你只需要知道数据库引擎的接口就足够了。\n",
       "注：你还要知道数据平台，中间件平台，安全平台，网络平台，运维平台，等等（你必要了解的领域太大了） 这样你才能在架构设计中，知道业务领域的流程，规则和数据模型等 。\n",
       "（附： 这里有很多的流程和规则，你需要花大力气去了解这些规则和流程引擎引擎内部的实现，引擎引擎内部的实现和业务领域的实现太不一样了，你需要花大力气去整合整合整合，你需要需要有很丰富的经验才能整合得起来，这里需要有大量的实践经验去积累。）\n",
       "二、学习设计模式（了解设计模式）\n",
       "（这里需要了解的设计模式太多太多太多，你至少需要了解和掌握一些常用的设计模式，比如单例模式，工厂模式，工厂模式，观察者模式，等等，这里不再细说， 这里推荐两本比较好的设计模式方面的书籍《设计模式》和《设计模式实用指南》。（你还可以看看《Ruby on Rails 设计模式》这本书，《Spring 核心概念》等）\n",
       "注：你需要知道，不同的设计模式，不同的场景，不同的需求，不同的业务流程，会用到不同的设计模式。你需要根据不同的需求，不同的业务流程去选择不同的设计模式，而不是，统一地用一种设计模式。你需要知道如何去用设计模式（你至少需要会写一些设计模式） 。\n",
       "来自：酷壳网 CoolShell\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = \"给立志成为架构师的程序员一些建议吧\"\n",
    "\n",
    "make_inference(question, qa_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f52a03-fa14-4df8-97e4-2358c2d8ce78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
